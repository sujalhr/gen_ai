import gensim.downloader as api
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

print("Loading model...")
model = api.load("glove-wiki-gigaword-100")
print("Model loaded.\n")

words = ['computer', 'internet', 'software', 'hardware', 'keyboard', 'mouse', 'server', 'network', 'programming', 'database']
vectors = [model[word] for word in words]

reduced = PCA(n_components=2).fit_transform(vectors)

input_word = 'computer'
print(f"Top 5 words similar to '{input_word}':")
for word, score in model.most_similar(input_word, topn=5):
    print(f"{word}: {score:.4f}")

plt.figure(figsize=(8, 6))
for i, word in enumerate(words):
    x, y = reduced[i]
    plt.scatter(x, y)
    plt.annotate(word, (x, y))
plt.title("Technology Word Embeddings (PCA)")
plt.grid(True)
plt.show()
